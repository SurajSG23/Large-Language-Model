{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e17bd4f9-04c7-49aa-973b-e44a99f1daa4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Environment Setup\n",
    "\n",
    "conda create --prefix D:\\AI-ML\\LLM\\llms_course_env python=3.11 -y\n",
    "\n",
    "conda activate D:\\AI-ML\\LLM\\llms_course_env\n",
    "\n",
    "conda install -c conda-forge jupyter ipykernel -y\n",
    "\n",
    "python -m ipykernel install --user --name=llms_course_env --display-name \"Python (llms_course_env)\"\n",
    "\n",
    "(D:\\AI-ML\\LLM\\llms_course_env) D:\\AI-ML\\LLM>jupyter notebook\n",
    "\n",
    "In the notebook interface, go to Kernel → Change Kernel → Python (llms_course_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35655027-9585-4937-8972-db8495d7502d",
   "metadata": {},
   "source": [
    "# OpenAI Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90ef5c7c-02f1-45ac-a28b-db130d61531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import certifi\n",
    "from openai import OpenAI\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd72be12-abe0-4a7d-aa96-5cc99b46a214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix SSL verification issues\n",
    "os.environ[\"SSL_CERT_FILE\"] = certifi.where()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4ee4543-9f3e-43a2-97b0-8731646d4b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize client correctly\n",
    "client = OpenAI(api_key=config.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5766dc5a-c981-4b7f-a9d8-84ccb96a2f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=10,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ab2b5e-a981-4947-8894-00cf742bbdf2",
   "metadata": {},
   "source": [
    "### Gemini AI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b02c1186-c45b-4c92-8405-0ff9e87c78fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "import config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c186b68-ad17-4fbb-b4fd-a391d9ced089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Gemini API\n",
    "genai.configure(api_key=config.gemini_api_key)\n",
    "\n",
    "# Initialize model\n",
    "model = genai.GenerativeModel(\"gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "feef2254-a589-416a-9637-448a93eeb266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt):\n",
    "    response = model.generate_content(\n",
    "        prompt,\n",
    "        generation_config={\n",
    "            \"temperature\": 0.8,\n",
    "            \"max_output_tokens\": 10\n",
    "        } \n",
    "    )\n",
    "    return response.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bf8eec7f-674f-4ea3-9c08-3889b24f692d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leonardo da Vinci painted the Mona Lisa.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Who painted Mona Lisa?\"\n",
    "print(generate_text(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03a4a10-3d89-48eb-8d9b-bcd4d037638b",
   "metadata": {},
   "source": [
    "### Key word text summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cb071f01-f801-4de5-994c-d6352d75ff09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_summarizer(prompt: str):\n",
    "    # Instruction + user text\n",
    "    instruction = (\n",
    "        \"You will be provided with a block of text, \"\n",
    "        \"and your task is to extract a list of keywords from it.\"\n",
    "    )\n",
    "\n",
    "    response = model.generate_content(\n",
    "        [\n",
    "            {\"role\": \"user\", \"parts\": [instruction]},  # System-like instruction\n",
    "            {\"role\": \"user\", \"parts\": [prompt]}        # User-provided text\n",
    "        ],\n",
    "        generation_config={\n",
    "            \"temperature\": 0.5,\n",
    "            \"max_output_tokens\": 256\n",
    "        }\n",
    "    )\n",
    "    return response.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "92d221f5-5b13-4438-8015-f445afade051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master Reef Guide Kirsty Whitman didn't need to tell me twice. Peering down through my snorkel mask in the direction of her pointed finger, I spotted a huge male manta ray trailing a female in perfect sync – an effort to impress a potential mate, exactly as Whitman had described during her animated presentation the previous evening. Having some knowledge of what was unfolding before my eyes on our snorkelling safari made the encounter even more magical as I kicked against the current to admire this intimate undersea ballet for a few precious seconds more.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Master Reef Guide Kirsty Whitman didn't need to tell me twice. Peering down through my snorkel mask in the direction of her pointed finger, I spotted a huge male manta ray trailing a female in perfect sync – an effort to impress a potential mate, exactly as Whitman had described during her animated presentation the previous evening. Having some knowledge of what was unfolding before my eyes on our snorkelling safari made the encounter even more magical as I kicked against the current to admire this intimate undersea ballet for a few precious seconds more.\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "203f32f6-89e3-4db7-aa1a-9fe9dd18be0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*   Master Reef Guide\n",
      "*   Kirsty Whitman\n",
      "*   manta ray\n",
      "*   snorkel mask\n",
      "*   snorkelling\n",
      "*   safari\n",
      "*   undersea ballet\n",
      "*   female\n",
      "*   male\n",
      "*   mate\n",
      "*   current\n",
      "*   presentation\n"
     ]
    }
   ],
   "source": [
    "print(text_summarizer(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91062d41-cd4a-4ac6-9489-c9251bcca0c5",
   "metadata": {},
   "source": [
    "## Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5196b65b-f6ac-47c3-837e-38dab71a1b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader  # Loads text/content directly from web pages (URLs)\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter  # Splits long documents into smaller chunks (tokens/characters) for processing\n",
    "from langchain.embeddings import OpenAIEmbeddings  # Converts text chunks into vector embeddings using OpenAI models\n",
    "from langchain.vectorstores import FAISS  # Stores and searches embeddings efficiently (vector database)\n",
    "from langchain.memory import ConversationBufferMemory  # Keeps track of past conversation history for context\n",
    "from langchain.llms import OpenAI  # Wrapper for OpenAI’s text completion models (e.g., davinci, gpt-3.5-turbo-instruct)\n",
    "from langchain.chains import ConversationalRetrievalChain  # Combines retrieval (FAISS) with a conversational LLM for Q&A\n",
    "from langchain.chat_models import ChatOpenAI  # Wrapper for OpenAI’s chat-based models (e.g., gpt-3.5-turbo, gpt-4)\n",
    "import config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1ecf87a-3fdd-4fba-9cb9-285cb1f86080",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://365datascience.com/upcoming-courses\"  \n",
    "# The webpage URL you want to extract text/content from\n",
    "\n",
    "loader = WebBaseLoader(url)  \n",
    "# Initializes a web loader that can scrape and load text from the given URL\n",
    "\n",
    "raw_documents = loader.load()  \n",
    "# Fetches the webpage content and returns it as a list of documents (usually with metadata like URL, title, etc.)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter()  \n",
    "# Creates a text splitter that breaks long documents into smaller chunks  \n",
    "# (helps avoid token limits and improves embedding + retrieval performance)\n",
    "\n",
    "documents = text_splitter.split_documents(raw_documents)  \n",
    "# Splits the raw documents into smaller text chunks while preserving metadata\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=config.api_key)  \n",
    "# Converts each text chunk into numerical vector embeddings using OpenAI’s embedding model  \n",
    "# (these embeddings are later stored in a vector database like FAISS for semantic search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afd27c0-3a28-4161-8747-df06e54154b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key = \"chat_history\", return_messages=True)\n",
    "\n",
    "qa = ConversationalRetrievalChain.from_llm(ChatOpenAI(openai_api_key=api_key, \n",
    "                                                  model=\"gpt-3.5-turbo\", \n",
    "                                                  temperature=0), \n",
    "                                                  vectorstore.as_retriever(), \n",
    "                                                  memory=memory\n",
    "                                          )\n",
    "\n",
    "query = \"What is the next course to be uploaded on the 365DataScience platform?\"\n",
    "\n",
    "result = qa({\"question\": query})\n",
    "\n",
    "result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3fcae1f-c8b9-465c-bfe1-af6014789648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Michael Jackson - WikipediaJump to contentMain menuMain menumove to sidebarhideNavigationMain pageContentsCurrent eventsRandom articleAbout WikipediaContact usContributeHelpLearn to editCommunity portalRecent changesUpload fileSpecial pagesSearchSearchAppearanceDonateCreate accountLog inPersonal toolsDonate Create account Log inPages for logged out editors learn moreContributionsTalkContentsmove to sidebarhide(Top)1Life and careerToggle Life and career subsection1.1Early life and the Jackson 5 ('"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extra:\n",
    "import re\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "# Load webpage\n",
    "loader2 = WebBaseLoader(\"https://en.wikipedia.org/wiki/Michael_Jackson\")\n",
    "raw_documents2 = loader2.load()\n",
    "\n",
    "# Extract just the text (page_content) from the documents\n",
    "text_data = \" \".join([doc.page_content for doc in raw_documents2])\n",
    "\n",
    "# Clean newlines\n",
    "cleaned_raw_documents = re.sub(r\"[\\n\\t]\", \"\", text_data)\n",
    "\n",
    "cleaned_raw_documents[:500]  # show first 500 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da71ebce-0c5f-4f73-91af-c3192e6020a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llms_course_env)",
   "language": "python",
   "name": "llms_course_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
